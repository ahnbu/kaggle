#### Structured Set에는 (Gradient Boost Machine)

residual = a - p
오차를 줄이기 위해서 조정하는 트리를 계속 만들어가면서,
오차 최소화시키는 방식.

10번 중 75% --> GBM
10번 중 15% --> RF
10번 중  5% --> SVM은 10만개 이상에서는 엄청 느려짐

가장 많이 쓰는게 XGBoost


colsample --> max_feature
col bylevel -> 

#### Unstructured Set에는 아직 그런 알고리즘이 없음 (딥러닝 연구중)



============================================================================================

#### 데이터 업무

도메인전문가(전문)
인공지능전문가(수학)
개발자


#### 머신러닝의 단점

예측은 잘하는데, 분석하기는 어려움.
어떻게 했는지 블랙박스..
예외적으로 분석할 때 쓰는 경우도 있지만..


#### Hyperparameter Tuning

머신러닝 = 스스로 paramater를 잡아주는 조건
hyperparameter (갈라주는 조건들) ==> 머신러닝이 찾지 못하는 패러미터, 이걸 잘 찾아주는게 노하우

RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
           oob_score=False, random_state=79, verbose=0, warm_start=False)

RF에서 중요한 하이퍼파라미터

트리개수 n_estimators (기본값은 10개, 높을수록 좋지만, 너무 많아지면 느려짐. 좋아지는 정도가 매우 작아짐 => 시간 없으면 100, 많으면 300)
트리깊이 max_depth (너무 커도 안좋고, 너무 작아도 안좋음). 규모에 따라서 선택 3,5,7,9,11
피처샘플링 max_features (0.7면, 트리만들때마다 70%만 써).


=============== Grid Search =========================

가장 좋은 hyperparameter가 안나온다.
근처까지만 간다. 구역만 정의해주는 것으로 끝난다.

=============== Random Search =======================

Coarse Search ==> Fine(r) Search
100번               100번
100개 컴퓨터에서 100번 돌려서 가져오는 분산 방식 ==> 지원되는 곳에서는

각 파라미터별 100번 돌려서 top 5개의 범위를 입력해서, random search한다.


#####

레이블 --> 측정공식 --> 

*측정공식이 복잡할 수록, 그 원리에 답이 있다.
*clipping, 아웃라이어를 쳐낸다. (900이상은 900으로 한다.)


#### 레이블에 맞춰서 예측모델을 만들어낸다.

*레이블에 log+1을 씌워서 측정한다.
0.38 --> 0.09 (로그를 2번 씌워서, RMSLE --> RMSE로 바꿔야)
0.38 --> 0.37
(Kaggle 0.43 -->(레이블로그)0.40 -->(하이퍼)0.39)
np.exp() = 1


####

전자 (간단한 코드, 어려운 모델)
후자 (복잡한 코드, 간단한 모델) ==> 범용성 높아서 추천함




=================================================================================


Evaluation Metric...

Accuracy = 정답률 (타이타닉 같은 문제)
--> regression 문제에서는 쓰기 어려움. (틀린 정도가 중요해지니까)

###

MAE (평균절대) -> 
MSE (평균제곱) -> 에러가 클수록 더 강조하는 모델 (모델간 차이가 더 커짐)
RMSE (루트평균제곱) -> 2번 결과값에 루트를 씌워준 것.
RMSLE (루트평균제곱로그) -> log를 씌워서, 1~2개 에러가 커져도 그것 때문에 영향이 크지 않도록.

MAE
MSE
MSLE
==> 이런 것은 이미 있다.


###

원하는 작업의 목표와 일치하는 평가지표를 선택하면 된다.
offline evaluation (예측) vs. online evaluation (현업)

###

churn rate (이탈률)
retention time (잔존시간)

cac(customer acquisition cost) : ltv(lifetime value) = 1 : 3
획득비용 : 발생매출

###

DAU같은 것을 측정하는데, 

----------------------------------------------------------------------------

###

카카오택시라면, 빠른 것보다, 느린 게 더 큰 페널티 주도록, 할 수 있음.

-----------------------------------------------------------------------------

###

Cross valuation ==> 온라인 스코어간에 경향성이 일치하도록 만들도록 해야 함.

==>> 현실적으로 일치하기 어려운 경우가 있다.
==>> 무엇때문에 일치하지 않는지는 알아야 (예. bike sharing의 datetime의 경우)

==>> 이걸 반영할 때에는 cross valuation 숫자보다는 Kaggle Score를 기대하는게 좋다.

-----------------------------------------------------------------------------

# 구글 테스트

Deep Learning Neural Networks for Youtube Recommendation
"동영상의 나이"
"이미 본 사람들의 "

새로운 개념...

CV는 별로 개선되지 않았는데, 개념적으로 말이 되니까.
올려서 일부 테스트 그룹에 올려봤는데, 좋았다. (A/B 테스트)

20% -> 10% (하루 1번 점수 올린다. 목표)
10% ->  5% (1주 1번 점수 올린다. 목표)
